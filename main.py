import os
from telegram import Update, InputFile
from telegram.constants import ChatAction
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes

from moviepy.editor import ImageClip, AudioFileClip, concatenate_videoclips
from gtts import gTTS
from PIL import Image
import requests
import openai

# ============================
# üîë ENV VARIABLES
# ============================
BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

openai.api_key = OPENAI_API_KEY


# ============================
# üî• /start
# ============================
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–∑–¥–∞—ë—Ç –≤–∏–¥–µ–æ –ø–æ —Ç–≤–æ–µ–º—É —Å—Ü–µ–Ω–∞—Ä–∏—é üé¨.\n\n"
        "–û—Ç–ø—Ä–∞–≤—å –º–Ω–µ —Ç–µ–∫—Å—Ç, –∏ —è —Å–¥–µ–ª–∞—é –≤–∏–¥–µ–æ!"
    )


# ============================
# üî• –°–æ–∑–¥–∞–Ω–∏–µ AI –∫–∞—Ä—Ç–∏–Ω–∫–∏
# ============================
def generate_image(prompt):
    url = "https://api.openai.com/v1/images/generations"
    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}"}
    payload = {"prompt": prompt, "size": "1024x1024"}

    response = requests.post(url, headers=headers, json=payload).json()
    image_url = response["data"][0]["url"]

    img = Image.open(requests.get(image_url, stream=True).raw)
    img.save("frame.png")

    return "frame.png"


# ============================
# üî• –°–æ–∑–¥–∞–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤–æ–π –¥–æ—Ä–æ–∂–∫–∏
# ============================
def generate_voice(text):
    tts = gTTS(text, lang="ru")
    tts.save("voice.mp3")
    return "voice.mp3"


# ============================
# üî• –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–¥–µ–æ
# ============================
def generate_video(image_path, audio_path):
    img_clip = ImageClip(image_path).set_duration(7)
    audio = AudioFileClip(audio_path)
    img_clip = img_clip.set_audio(audio)
    img_clip.write_videofile("result.mp4", fps=24)
    return "result.mp4"


# ============================
# üî• AI –æ—Ç–≤–µ—Ç (–æ–ø–∏—Å–∞–Ω–∏–µ + —É–ª—É—á—à–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞)
# ============================
def improve_prompt(text):
    response = openai.ChatCompletion.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": f"–ü–µ—Ä–µ–ø–∏—à–∏ –∫—Ä–∞—Å–∏–≤–æ —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç: {text}"}],
    )
    return response["choices"][0]["message"]["content"]


# ============================
# üî• –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è (–≥–ª–∞–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞)
# ============================
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_text = update.message.text

    await update.message.reply_chat_action(ChatAction.TYPING)
    improved = improve_prompt(user_text)

    await update.message.reply_text("–°–æ–∑–¥–∞—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ‚Ä¶")
    img = generate_image(improved)

    await update.message.reply_text("–°–æ–∑–¥–∞—é –æ–∑–≤—É—á–∫—É‚Ä¶")
    voice = generate_voice(improved)

    await update.message.reply_text("–°–æ–±–∏—Ä–∞—é –≤–∏–¥–µ–æ‚Ä¶")
    video = generate_video(img, voice)

    await update.message.reply_video(video=InputFile("result.mp4"))


# ============================
# üî• MAIN
# ============================
def main():
    app = ApplicationBuilder().token(BOT_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT, handle_message))

    print("Bot started!")
    app.run_polling()


if __name__ == "__main__":
    main()
